{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c815117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score, classification_report,\n",
    "    confusion_matrix, roc_auc_score\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(),  '..', 'src'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "from data_preprocess import DataCleaner, DataPreprocessor\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score, roc_auc_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "from mlflow.models.signature import infer_signature\n",
    "import mlflow\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ec0625c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/07 23:50:03 INFO mlflow.tracking.fluent: Experiment with name 'alerta_certificado_invalido_v3' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/924702083764126140', creation_time=1746679803865, experiment_id='924702083764126140', last_update_time=1746679803865, lifecycle_stage='active', name='alerta_certificado_invalido_v3', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ================================\n",
    "# 1. CONFIGURACI√ìN\n",
    "# ================================\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"alerta_certificado_invalido_v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18e6507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_excel(r'../data/raw/Incapacidades_Empresa.xlsx')\n",
    "features =  pd.read_csv(r'../data/processed/features.csv').iloc[:, 0].to_list()\n",
    "\n",
    "# Limpieza\n",
    "cleaner = DataCleaner(df_raw)\n",
    "df_clean = cleaner.limpiar()\n",
    "\n",
    "# Preprocesamiento\n",
    "processor = DataPreprocessor(df_clean, target='alerta_certificado_invalido')\n",
    "df_ready = processor.procesar()\n",
    "df = df_ready.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6edf07b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ X_train: (5022, 373), y_train: (5022,)\n",
      "‚úÖ X_test: (558, 373), y_test: (558,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=[\"alerta_certificado_invalido\",\"c.c_colaborador\"])\n",
    "X = X[features]\n",
    "y = df[\"alerta_certificado_invalido\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42, stratify=y\n",
    ")\n",
    "y_test = y_test.astype(int)\n",
    "print(f\"‚úÖ X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"‚úÖ X_test: {X_test.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce4dfc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Buscando mejores hiperpar√°metros...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sojua\\OneDrive\\Desktop\\uell\\env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RandomForest -> F1: 0.3667, Precision: 0.5347, Recall: 0.2790, AUC: 0.5657\n",
      "üìä Confusion Matrix:\n",
      " [[215  67]\n",
      " [199  77]]\n",
      "üßæ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.76      0.62       282\n",
      "           1       0.53      0.28      0.37       276\n",
      "\n",
      "    accuracy                           0.52       558\n",
      "   macro avg       0.53      0.52      0.49       558\n",
      "weighted avg       0.53      0.52      0.49       558\n",
      "\n",
      "üèÉ View run RandomForest_HPO at: http://127.0.0.1:5000/#/experiments/924702083764126140/runs/ac440ff2243d468098635660e89c35e0\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/924702083764126140\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 3. GRIDSEARCHCV + RANDOM FOREST\n",
    "# ================================\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 300],\n",
    "    'max_depth': [ 10, 20, 30],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['log2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# 4. ENTRENAMIENTO + LOGGING RF\n",
    "# ================================\n",
    "with mlflow.start_run(run_name=\"RandomForest_HPO\"):\n",
    "\n",
    "    print(\"üîç Buscando mejores hiperpar√°metros...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = y_pred.astype(int)\n",
    "\n",
    "    # M√©tricas\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "    mlflow.log_params(grid_search.best_params_)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"roc_auc\", auc)\n",
    "\n",
    "    input_example = X_test.iloc[:1]\n",
    "    signature = infer_signature(X_test, y_pred)\n",
    "\n",
    "    mlflow.sklearn.log_model(best_model, \"RandomForest_best\", signature=signature, input_example=input_example)\n",
    "\n",
    "    print(\"‚úÖ RandomForest -> F1: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, AUC: {:.4f}\".format(f1, precision, recall, auc))\n",
    "    print(\"üìä Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"üßæ Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11c45bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sojua\\OneDrive\\Desktop\\uell\\env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:51:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ XGBoost -> F1: 0.4851, Precision: 0.5000, Recall: 0.4710, AUC: 0.5231\n",
      "üèÉ View run XGBoostClassifier at: http://127.0.0.1:5000/#/experiments/924702083764126140/runs/ad08ba4c85c44aacb82b31c81b594500\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/924702083764126140\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 5. ENTRENAMIENTO XGBoost\n",
    "# ================================\n",
    "with mlflow.start_run(run_name=\"XGBoostClassifier\"):\n",
    "\n",
    "    y_train = y_train.astype(int)  # Asegura que sean enteros\n",
    "    class_counts = Counter(y_train)\n",
    "\n",
    "    neg = class_counts.get(0, 0)\n",
    "    pos = class_counts.get(1, 1)  # evita divisi√≥n por cero\n",
    "\n",
    "    scale_pos_weight = neg / pos\n",
    "\n",
    "    xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss',\n",
    "                              scale_pos_weight=scale_pos_weight, random_state=42)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    y_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = y_pred.astype(int)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "    mlflow.log_param(\"scale_pos_weight\", scale_pos_weight)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"roc_auc\", auc)\n",
    "\n",
    "    signature = infer_signature(X_test, y_pred)\n",
    "    mlflow.sklearn.log_model(xgb_model, \"XGBoost\", signature=signature, input_example=X_test.iloc[:1])\n",
    "\n",
    "    print(\"‚úÖ XGBoost -> F1: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, AUC: {:.4f}\".format(f1, precision, recall, auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9ac3c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 2487, number of negative: 2535\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 5022, number of used features: 104\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "‚úÖ LightGBM -> F1: 0.4901, Precision: 0.4875, Recall: 0.4928, AUC: 0.4945\n",
      "üèÉ View run LightGBMClassifier at: http://127.0.0.1:5000/#/experiments/924702083764126140/runs/9a769fd16c624f8fb9937f28b8553930\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/924702083764126140\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 6. ENTRENAMIENTO LightGBM\n",
    "# ================================\n",
    "with mlflow.start_run(run_name=\"LightGBMClassifier\"):\n",
    "\n",
    "    lgb_model = LGBMClassifier(class_weight='balanced', random_state=42)\n",
    "    lgb_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = lgb_model.predict(X_test)\n",
    "    y_proba = lgb_model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = y_pred.astype(int)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"roc_auc\", auc)\n",
    "\n",
    "    signature = infer_signature(X_test, y_pred)\n",
    "    mlflow.sklearn.log_model(lgb_model, \"LightGBM\", signature=signature, input_example=X_test.iloc[:1])\n",
    "\n",
    "    print(\"‚úÖ LightGBM -> F1: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, AUC: {:.4f}\".format(f1, precision, recall, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5a4d979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Buscando mejores hiperpar√°metros para regresi√≥n log√≠stica...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sojua\\OneDrive\\Desktop\\uell\\env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "c:\\Users\\sojua\\OneDrive\\Desktop\\uell\\env\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mejor configuraci√≥n encontrada: {'C': 10.0, 'l1_ratio': 0.0, 'solver': 'saga'}\n",
      "üéØ F1: 0.5620 | Precision: 0.5662 | Recall: 0.5580 | AUC: 0.6209\n",
      "üìä Confusion Matrix:\n",
      " [[164 118]\n",
      " [122 154]]\n",
      "üßæ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.58      0.58       282\n",
      "           1       0.57      0.56      0.56       276\n",
      "\n",
      "    accuracy                           0.57       558\n",
      "   macro avg       0.57      0.57      0.57       558\n",
      "weighted avg       0.57      0.57      0.57       558\n",
      "\n",
      "üèÉ View run LogisticRegression_HPO at: http://127.0.0.1:5000/#/experiments/924702083764126140/runs/bb9c6b87173c4c8a8187847edf2a1b32\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/924702083764126140\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score, roc_auc_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "from mlflow.models.signature import infer_signature\n",
    "import mlflow\n",
    "\n",
    "# Asegura que y_train es num√©rico\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "# ================================\n",
    "# GRIDSEARCHCV + LOGISTIC REGRESSION\n",
    "# ================================\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1.0, 10.0],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'l1_ratio': [0.0, 0.5, 1.0]  # solo para elasticnet\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# ENTRENAMIENTO + LOGGING\n",
    "# ================================\n",
    "with mlflow.start_run(run_name=\"LogisticRegression_HPO\"):\n",
    "\n",
    "    print(\"üîç Buscando mejores hiperpar√°metros para regresi√≥n log√≠stica...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # M√©tricas\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "    # Logging\n",
    "    mlflow.log_params(grid_search.best_params_)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"roc_auc\", auc)\n",
    "\n",
    "    signature = infer_signature(X_test, y_pred)\n",
    "    mlflow.sklearn.log_model(\n",
    "        best_model,\n",
    "        \"LogisticRegression_best\",\n",
    "        signature=signature,\n",
    "        input_example=X_test.iloc[:1]\n",
    "    )\n",
    "\n",
    "    print(\"‚úÖ Mejor configuraci√≥n encontrada:\", grid_search.best_params_)\n",
    "    print(f\"üéØ F1: {f1:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f} | AUC: {auc:.4f}\")\n",
    "    print(\"üìä Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"üßæ Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
